{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526c0690",
   "metadata": {},
   "source": [
    "# EE511 Final Project\n",
    "\n",
    "In this file we train the SqueezeNet model as described in the paper found [here](https://arxiv.org/abs/1602.07360).\n",
    "This implementation uses the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e8316b",
   "metadata": {},
   "source": [
    "## Task 1: Train SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e9853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T00:05:20.734789Z",
     "iopub.status.busy": "2025-12-06T00:05:20.734177Z",
     "iopub.status.idle": "2025-12-06T00:05:25.085084Z",
     "shell.execute_reply": "2025-12-06T00:05:25.083949Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.ao.quantization import QuantStub, DeQuantStub\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device={device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a33ed",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The class in this cell below defines our architecture and defines our forward pass. We insert quantization stub for later Quantization Aware Training. We also define helper functions to save and load the model.\n",
    "\n",
    "Note: MSR Initialization was added because the training would not work without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ae5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T00:05:25.088954Z",
     "iopub.status.busy": "2025-12-06T00:05:25.088242Z",
     "iopub.status.idle": "2025-12-06T00:05:25.103227Z",
     "shell.execute_reply": "2025-12-06T00:05:25.102220Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class Fire(nn.Module):\n",
    "    def __init__(self, inplanes, squeeze_planes, expand_planes):\n",
    "        super(Fire, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        # self.bn1 = nn.BatchNorm2d(squeeze_planes)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(squeeze_planes, expand_planes, kernel_size=1)\n",
    "        # self.bn2 = nn.BatchNorm2d(expand_planes)\n",
    "        # self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(squeeze_planes, expand_planes, kernel_size=3, padding=1)\n",
    "        # self.bn3 = nn.BatchNorm2d(expand_planes)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # MSR initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        # out1 = self.bn2(self.conv2(x))\n",
    "        # out2 = self.bn3(self.conv3(x))\n",
    "        # out = torch.cat([out1, out2], 1)\n",
    "        # out = self.relu2(out)\n",
    "        # return out\n",
    "\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        out1 = self.conv2(x)\n",
    "        out2 = self.conv3(x)\n",
    "        out = torch.cat([out1, out2], 1)\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "class SqueezeNetCIFAR10(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SqueezeNetCIFAR10, self).__init__()\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1)\n",
    "        # # self.bn1 = nn.BatchNorm2d(96)\n",
    "        # self.relu = nn.ReLU(inplace=True)\n",
    "        # self.maxpool1 = nn.MaxPool2d(2, 2)  # 32 -> 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "\n",
    "        self.fire2 = Fire(96, 16, 64)\n",
    "        self.fire3 = Fire(128, 16, 64)\n",
    "        self.fire4 = Fire(128, 32, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)  # 16 -> 8\n",
    "\n",
    "        self.fire5 = Fire(256, 32, 128)\n",
    "        self.fire6 = Fire(256, 48, 192)\n",
    "        self.fire7 = Fire(384, 48, 192)\n",
    "        self.fire8 = Fire(384, 64, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(2, 2)  # 8 -> 4\n",
    "\n",
    "        self.fire9 = Fire(512, 64, 256)\n",
    "        self.conv10 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.avg_pool = nn.AvgPool2d(4)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        # x = self.relu(self.bn1(self.conv1(x)))\n",
    "        # x = self.relu(self.conv1(x))\n",
    "        x = self.maxpool1(self.conv1(x))\n",
    "\n",
    "        x = self.fire2(x)\n",
    "        x = self.fire3(x)\n",
    "        x = self.fire4(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.fire5(x)\n",
    "        x = self.fire6(x)\n",
    "        x = self.fire7(x)\n",
    "        x = self.fire8(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x = self.fire9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dequant(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def load_model(self, path='squeezenet_cifar10.pth',device='cpu'):\n",
    "        state_dict = torch.load(path,map_location=device)\n",
    "\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            if k.startswith('module.'):\n",
    "                k = k[len('module.'):]\n",
    "            new_state_dict[k] = v\n",
    "\n",
    "        self.load_state_dict(new_state_dict)\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "\n",
    "        print(f\"Model loaded from {path}\")\n",
    "        # print(self)\n",
    "\n",
    "    def save_model(self, path='squeezenet_cifar10.pth'):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        print(f\"Model saved to {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a2464",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "In this cell we define a function to load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadba32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T00:05:25.107452Z",
     "iopub.status.busy": "2025-12-06T00:05:25.107191Z",
     "iopub.status.idle": "2025-12-06T00:05:25.113225Z",
     "shell.execute_reply": "2025-12-06T00:05:25.112310Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(path='./data', batch_size=64):\n",
    "  print(\"Loading the CIFAR10 dataset\")\n",
    "\n",
    "  test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(), # scale RGB 0-255 to 0-1\n",
    "    # normalize with known mean and std deviation of the CIFAR10 dataset\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "  ])\n",
    "\n",
    "  train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                    (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  # get training data\n",
    "  train_dataset = datasets.CIFAR10(root=path, train=True, download=True, transform=train_transform)\n",
    "  # get test data\n",
    "  test_dataset = datasets.CIFAR10(root=path, train=False, download=True, transform=test_transform)\n",
    "  # load the training data\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "  # load the test data\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "  print(f\"Loaded train data: {len(train_loader.dataset)} total samples, {len(train_loader)} batches\\n\"\n",
    "      f\"Loaded test data: {len(test_loader.dataset)} total samples, {len(test_loader)} batches\")\n",
    "\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d80055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T00:05:25.116497Z",
     "iopub.status.busy": "2025-12-06T00:05:25.116206Z",
     "iopub.status.idle": "2025-12-06T00:05:41.064529Z",
     "shell.execute_reply": "2025-12-06T00:05:41.062840Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb673199",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In the cells below we define a function to visualize our training and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82cd0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T00:05:41.070938Z",
     "iopub.status.busy": "2025-12-06T00:05:41.070608Z",
     "iopub.status.idle": "2025-12-06T00:05:41.544730Z",
     "shell.execute_reply": "2025-12-06T00:05:41.543503Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(metrics):\n",
    "  train_losses = metrics.get('train_loss',None)\n",
    "  test_losses = metrics.get('test_loss',None)\n",
    "  train_accs = metrics.get('train_acc',None)\n",
    "  test_accs = metrics.get('test_acc',None)\n",
    "\n",
    "  epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "  plt.figure(figsize=(12, 5))\n",
    "\n",
    "  # Loss Graph\n",
    "  plt.subplot(1, 2, 1)\n",
    "  if train_losses:\n",
    "    plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "  if test_losses:\n",
    "    plt.plot(epochs, test_losses, label='Test Loss', marker='s')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.title('Training vs Test Loss')\n",
    "  plt.legend()\n",
    "  plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "  # Accuracy Graph\n",
    "  plt.subplot(1, 2, 2)\n",
    "  if train_accs:\n",
    "    plt.plot(epochs, train_accs, label='Train Accuracy', marker='o')\n",
    "  if test_accs:\n",
    "    plt.plot(epochs, test_accs, label='Test Accuracy', marker='s')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy (%)')\n",
    "  plt.title('Training vs Test Accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f93e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T00:05:41.550795Z",
     "iopub.status.busy": "2025-12-06T00:05:41.550093Z",
     "iopub.status.idle": "2025-12-06T00:05:41.560466Z",
     "shell.execute_reply": "2025-12-06T00:05:41.559523Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model,train_loader,test_loader,train=True,test=True,device='cpu',epochs=10,lr=1e-3):\n",
    "  model.to(device)\n",
    "  metrics = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "\n",
    "  # TRAINING LOOP\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "  for e in range(epochs):\n",
    "    print(f\"Epoch [{e+1}/{epochs}] \",end='')\n",
    "    if train:\n",
    "      model.train()\n",
    "      train_loss, total_examples, correct = 0.0, 0, 0\n",
    "\n",
    "      for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "        outputs = model(inputs) # forward pass\n",
    "        loss = criterion(outputs,labels) # get loss from cost function\n",
    "        loss.backward() # backward propagation\n",
    "        optimizer.step() # update gradients\n",
    "\n",
    "        # train_loss += loss.item() # track total loss up to this point\n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        _, pred_ind = outputs.max(1) # get index of prediction (highest value)\n",
    "        total_examples += labels.size(0) # update count for this epoch with batch size\n",
    "        correct += pred_ind.eq(labels).sum().item() # return count of correct predictions\n",
    "\n",
    "    #   train_loss /= len(train_loader) # get average per batch\n",
    "      train_loss /= total_examples # get average per example\n",
    "      train_acc = 100.0 * correct / total_examples\n",
    "\n",
    "      metrics[\"train_loss\"].append(train_loss)\n",
    "      metrics[\"train_acc\"].append(train_acc)\n",
    "\n",
    "      print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% \",end='')\n",
    "\n",
    "      # VALIDATION/TEST\n",
    "    if test:\n",
    "      model.eval()\n",
    "      test_loss, total_examples, correct = 0.0, 0, 0\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = model(inputs) # forward pass\n",
    "          loss = criterion(outputs,labels) # get loss from cost function\n",
    "          test_loss += loss.item() # update loss\n",
    "          _, pred_ind = outputs.max(1) # get index of prediction (highest value)\n",
    "          total_examples += labels.size(0) # update count for this epoch with batch size\n",
    "          correct += pred_ind.eq(labels).sum().item() # return count of correct predictions\n",
    "\n",
    "      test_loss /= len(test_loader)\n",
    "      test_acc = 100.0 * correct / total_examples\n",
    "\n",
    "      metrics[\"test_loss\"].append(test_loss)\n",
    "      metrics[\"test_acc\"].append(test_acc)\n",
    "\n",
    "      print(f\"Test/Val Loss: {test_loss:.4f}, Test/Val Acc: {test_acc:.2f}%\")\n",
    "\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de683d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T00:05:41.565568Z",
     "iopub.status.busy": "2025-12-06T00:05:41.564981Z",
     "iopub.status.idle": "2025-12-06T00:05:41.671520Z",
     "shell.execute_reply": "2025-12-06T00:05:41.670413Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fp32 = SqueezeNetCIFAR10()\n",
    "# model_fp32.load_model('squeezenet2_cifar10_fp32.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = True, True\n",
    "epochs = 150\n",
    "fp32_metrics = train_model(model=model_fp32,train_loader=train_loader,test_loader=test_loader,train=train,test=test,device=device,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6d031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T03:46:16.175870Z",
     "iopub.status.busy": "2025-12-06T03:46:16.175565Z",
     "iopub.status.idle": "2025-12-06T03:46:16.225563Z",
     "shell.execute_reply": "2025-12-06T03:46:16.224431Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fp32.save_model(\"squeezenet2_cifar10_fp32.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b0758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T03:46:16.230425Z",
     "iopub.status.busy": "2025-12-06T03:46:16.229782Z",
     "iopub.status.idle": "2025-12-06T03:46:16.734545Z",
     "shell.execute_reply": "2025-12-06T03:46:16.732875Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metrics(fp32_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0abd46",
   "metadata": {},
   "source": [
    "## Task 2: Quantize Squeezenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9164e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T03:46:16.738854Z",
     "iopub.status.busy": "2025-12-06T03:46:16.738221Z",
     "iopub.status.idle": "2025-12-06T03:46:16.743780Z",
     "shell.execute_reply": "2025-12-06T03:46:16.742935Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.ao.quantization import get_default_qat_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_qat_fx, convert_fx\n",
    "\n",
    "model_qat = SqueezeNetCIFAR10()\n",
    "model_qat.load_model(\"squeezenet2_cifar10_fp32.pth\", device='cpu')\n",
    "model_qat.eval()\n",
    "\n",
    "# example input for FX tracing\n",
    "example_inputs = (torch.randn(1, 3, 224, 224, device='cpu'),)\n",
    "\n",
    "# QAT config dictionary, default 8-bit symmetric QAT\n",
    "qconfig_dict = {\"\": get_default_qat_qconfig('fbgemm')}\n",
    "\n",
    "# prepare the model for QAT\n",
    "model_qat_prepared = prepare_qat_fx(model_qat, qconfig_dict, example_inputs=example_inputs)\n",
    "\n",
    "model_qat_prepared.to(device)\n",
    "model_qat_prepared.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a03413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T03:46:16.748320Z",
     "iopub.status.busy": "2025-12-06T03:46:16.747947Z",
     "iopub.status.idle": "2025-12-06T03:46:16.751363Z",
     "shell.execute_reply": "2025-12-06T03:46:16.750623Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = True, True\n",
    "epochs = 50\n",
    "qat_metrics = train_model(model=model_qat_prepared,train_loader=train_loader,test_loader=test_loader,train=train,test=test,device=device,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc3f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T03:46:16.755605Z",
     "iopub.status.busy": "2025-12-06T03:46:16.755326Z",
     "iopub.status.idle": "2025-12-06T03:46:16.758533Z",
     "shell.execute_reply": "2025-12-06T03:46:16.757844Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_metrics(qat_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c39ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T03:46:16.762441Z",
     "iopub.status.busy": "2025-12-06T03:46:16.762071Z",
     "iopub.status.idle": "2025-12-06T03:46:16.765812Z",
     "shell.execute_reply": "2025-12-06T03:46:16.765034Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert to INT8\n",
    "model_qat_prepared.eval()\n",
    "model_int8 = convert_fx(model_qat_prepared.cpu())\n",
    "torch.save(model_int8.state_dict(), \"squeezenet2_int8_qat.pth\")\n",
    "# model_int8.load_state_dict(torch.load(\"squeezenet_int8_qat.pth\"))\n",
    "# model_int8.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506aea53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T03:46:16.769952Z",
     "iopub.status.busy": "2025-12-06T03:46:16.769615Z",
     "iopub.status.idle": "2025-12-06T03:46:16.773909Z",
     "shell.execute_reply": "2025-12-06T03:46:16.772987Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to('cpu'), labels.to('cpu')\n",
    "            outputs = model(images)\n",
    "            _, pred = outputs.max(1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    return acc\n",
    "\n",
    "acc = evaluate(model_int8,test_loader)\n",
    "print(f\"INT8 Test Accuracy: {acc}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
