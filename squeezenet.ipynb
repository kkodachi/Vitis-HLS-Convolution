{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526c0690",
   "metadata": {},
   "source": [
    "# EE511 Final Project\n",
    "\n",
    "In this file we train the SqueezeNet model as described in the paper found [here](https://arxiv.org/abs/1602.07360).\n",
    "This implementation uses the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e8316b",
   "metadata": {},
   "source": [
    "## Task 1: Train SqueezeNet\n",
    "\n",
    "For task 1 we train SqueezeNet for 100 epochs and are able to get a final test accuracy of 69.66%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004e9853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:07:31.340167Z",
     "iopub.status.busy": "2025-12-07T21:07:31.339685Z",
     "iopub.status.idle": "2025-12-07T21:07:41.754919Z",
     "shell.execute_reply": "2025-12-07T21:07:41.754368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device=cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.ao.quantization import QuantStub, DeQuantStub\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device={device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a33ed",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The class in this cell below defines our architecture and defines our forward pass. We insert quantization stub for later Quantization Aware Training. We also define helper functions to save and load the model.\n",
    "\n",
    "Note: MSR Initialization was added because the training would not work without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ae5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:07:41.760192Z",
     "iopub.status.busy": "2025-12-07T21:07:41.759638Z",
     "iopub.status.idle": "2025-12-07T21:07:41.776575Z",
     "shell.execute_reply": "2025-12-07T21:07:41.775478Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "class Fire(nn.Module):\n",
    "    def __init__(self, inplanes, squeeze_planes, expand_planes):\n",
    "        super(Fire, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(squeeze_planes, expand_planes, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(squeeze_planes, expand_planes, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # # MSR initialization\n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, nn.Conv2d):\n",
    "        #         n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
    "        #         m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        out1 = self.conv2(x)\n",
    "        out2 = self.conv3(x)\n",
    "        out = torch.cat([out1, out2], 1)\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "class SqueezeNetCIFAR10(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SqueezeNetCIFAR10, self).__init__()\n",
    "        # self.quant = QuantStub()\n",
    "        # self.dequant = DeQuantStub()\n",
    "\n",
    "        # self.upsample = nn.Upsample(size=224, mode='bilinear', align_corners=False)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.fire2 = Fire(96, 16, 64)\n",
    "        self.fire3 = Fire(128, 16, 64)\n",
    "        self.fire4 = Fire(128, 32, 128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.fire5 = Fire(256, 32, 128)\n",
    "        self.fire6 = Fire(256, 48, 192)\n",
    "        self.fire7 = Fire(384, 48, 192)\n",
    "        self.fire8 = Fire(384, 64, 256)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.fire9 = Fire(512, 64, 256)\n",
    "        self.conv10 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        self.avg_pool = nn.AvgPool2d(13)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.upsample(x)\n",
    "        # x = self.quant(x)\n",
    "        x = self.maxpool1(self.conv1(x))\n",
    "\n",
    "        x = self.fire2(x)\n",
    "        x = self.fire3(x)\n",
    "        x = self.fire4(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.fire5(x)\n",
    "        x = self.fire6(x)\n",
    "        x = self.fire7(x)\n",
    "        x = self.fire8(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x = self.fire9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # x = self.dequant(x)\n",
    "        return x\n",
    "    \n",
    "    def load_model(self, path='squeezenet_fp32.pth',device='cpu'):\n",
    "        state_dict = torch.load(path,map_location=device)\n",
    "\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            if k.startswith('module.'):\n",
    "                k = k[len('module.'):]\n",
    "            new_state_dict[k] = v\n",
    "\n",
    "        self.load_state_dict(new_state_dict)\n",
    "        self.to(device)\n",
    "        self.eval()\n",
    "\n",
    "        print(f\"Model loaded from {path}\")\n",
    "        # print(self)\n",
    "\n",
    "    def save_model(self, path='squeezenet_fp32.pth'):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        print(f\"Model saved to {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a2464",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "In this cell we define a function to load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadba32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:07:41.780071Z",
     "iopub.status.busy": "2025-12-07T21:07:41.779880Z",
     "iopub.status.idle": "2025-12-07T21:07:41.783912Z",
     "shell.execute_reply": "2025-12-07T21:07:41.783449Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(path='./data', batch_size=64):\n",
    "  print(\"Loading the CIFAR10 dataset\")\n",
    "\n",
    "  transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(), # scale RGB 0-255 to 0-1\n",
    "    # normalize with known mean and std deviation of the CIFAR10 dataset\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "  ])\n",
    "\n",
    "  # train_transform = transforms.Compose([\n",
    "  #   transforms.RandomCrop(32, padding=4),\n",
    "  #   transforms.RandomHorizontalFlip(),\n",
    "  #   transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "  #   transforms.ToTensor(),\n",
    "  #   transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "  #                   (0.2023, 0.1994, 0.2010)),\n",
    "  # ])\n",
    "  train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize before any augmentation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "  ])\n",
    "\n",
    "  # get training data\n",
    "  train_dataset = datasets.CIFAR10(root=path, train=True, download=True, transform=train_transform)\n",
    "  # get test data\n",
    "  test_dataset = datasets.CIFAR10(root=path, train=False, download=True, transform=transform)\n",
    "  # load the training data\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=8,pin_memory=True)\n",
    "  # load the test data\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=8,pin_memory=True)\n",
    "\n",
    "  print(f\"Loaded train data: {len(train_loader.dataset)} total samples, {len(train_loader)} batches\\n\"\n",
    "      f\"Loaded test data: {len(test_loader.dataset)} total samples, {len(test_loader)} batches\")\n",
    "\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d80055",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:07:41.787597Z",
     "iopub.status.busy": "2025-12-07T21:07:41.787287Z",
     "iopub.status.idle": "2025-12-07T21:07:57.481399Z",
     "shell.execute_reply": "2025-12-07T21:07:57.480752Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_dataset(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb673199",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In the cells below we define a function to visualize our training and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a82cd0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:07:57.491380Z",
     "iopub.status.busy": "2025-12-07T21:07:57.490749Z",
     "iopub.status.idle": "2025-12-07T21:07:58.132801Z",
     "shell.execute_reply": "2025-12-07T21:07:58.131917Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(metrics):\n",
    "  train_losses = metrics.get('train_loss',None)\n",
    "  test_losses = metrics.get('test_loss',None)\n",
    "  train_accs = metrics.get('train_acc',None)\n",
    "  test_accs = metrics.get('test_acc',None)\n",
    "\n",
    "  epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "  plt.figure(figsize=(12, 5))\n",
    "\n",
    "  # Loss Graph\n",
    "  plt.subplot(1, 2, 1)\n",
    "  if train_losses:\n",
    "    plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "  if test_losses:\n",
    "    plt.plot(epochs, test_losses, label='Test Loss', marker='s')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.title('Training vs Test Loss')\n",
    "  plt.legend()\n",
    "  plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "  # Accuracy Graph\n",
    "  plt.subplot(1, 2, 2)\n",
    "  if train_accs:\n",
    "    plt.plot(epochs, train_accs, label='Train Accuracy', marker='o')\n",
    "  if test_accs:\n",
    "    plt.plot(epochs, test_accs, label='Test Accuracy', marker='s')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Accuracy (%)')\n",
    "  plt.title('Training vs Test Accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9f93e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:07:58.137437Z",
     "iopub.status.busy": "2025-12-07T21:07:58.137153Z",
     "iopub.status.idle": "2025-12-07T21:07:58.143337Z",
     "shell.execute_reply": "2025-12-07T21:07:58.142866Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model,train_loader,test_loader,train=True,test=True,device='cpu',epochs=10,lr=1e-3):\n",
    "  model.to(device)\n",
    "  metrics = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "\n",
    "  # TRAINING LOOP\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "  criterion_test = nn.CrossEntropyLoss()\n",
    "  # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "  # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "\n",
    "  for e in range(epochs):\n",
    "    print(f\"Epoch [{e+1}/{epochs}] \",end='')\n",
    "    if train:\n",
    "      model.train()\n",
    "      train_loss, total_examples, correct = 0.0, 0, 0\n",
    "\n",
    "      for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True) # zero gradients\n",
    "        outputs = model(inputs) # forward pass\n",
    "        loss = criterion(outputs,labels) # get loss from cost function\n",
    "        loss.backward() # backward propagation\n",
    "        optimizer.step() # update gradients\n",
    "\n",
    "        # train_loss += loss.item() # track total loss up to this point\n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "        _, pred_ind = outputs.max(1) # get index of prediction (highest value)\n",
    "        total_examples += labels.size(0) # update count for this epoch with batch size\n",
    "        correct += pred_ind.eq(labels).sum().item() # return count of correct predictions\n",
    "\n",
    "      # scheduler.step() \n",
    "    #   train_loss /= len(train_loader) # get average per batch\n",
    "      train_loss /= total_examples # get average per example\n",
    "      train_acc = 100.0 * correct / total_examples\n",
    "\n",
    "      metrics[\"train_loss\"].append(train_loss)\n",
    "      metrics[\"train_acc\"].append(train_acc)\n",
    "\n",
    "      print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% \",end='')\n",
    "\n",
    "      # VALIDATION/TEST\n",
    "    if test:\n",
    "      model.eval()\n",
    "      test_loss, total_examples, correct = 0.0, 0, 0\n",
    "\n",
    "      with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "          inputs, labels = inputs.to(device), labels.to(device)\n",
    "          outputs = model(inputs) # forward pass\n",
    "          loss = criterion_test(outputs,labels) # get loss from cost function\n",
    "          test_loss += loss.item() * labels.size(0) # update loss\n",
    "          _, pred_ind = outputs.max(1) # get index of prediction (highest value)\n",
    "          total_examples += labels.size(0) # update count for this epoch with batch size\n",
    "          correct += pred_ind.eq(labels).sum().item() # return count of correct predictions\n",
    "\n",
    "      test_loss /= total_examples\n",
    "      test_acc = 100.0 * correct / total_examples\n",
    "\n",
    "      metrics[\"test_loss\"].append(test_loss)\n",
    "      metrics[\"test_acc\"].append(test_acc)\n",
    "\n",
    "      print(f\"Test/Val Loss: {test_loss:.4f}, Test/Val Acc: {test_acc:.2f}%\")\n",
    "\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de683d9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T21:07:58.147669Z",
     "iopub.status.busy": "2025-12-07T21:07:58.147223Z",
     "iopub.status.idle": "2025-12-07T21:07:58.179995Z",
     "shell.execute_reply": "2025-12-07T21:07:58.179293Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights_he(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias)\n",
    "        \n",
    "model_fp32 = SqueezeNetCIFAR10()\n",
    "model_fp32.apply(init_weights_he)\n",
    "# model_fp32.load_model('squeezenet_fp32.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = True, True\n",
    "# epochs = 100\n",
    "# fp32_metrics = train_model(model=model_fp32,train_loader=train_loader,test_loader=test_loader,train=train,test=test,device=device,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fp32.save_model(\"squeezenet_fp32.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0080d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics(fp32_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce7a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader,device='cpu'):\n",
    "  model.eval()\n",
    "  model.to(device)\n",
    "  correct, total = 0, 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for images, labels in test_loader:\n",
    "          images = images.to(device, non_blocking=True)\n",
    "          labels = labels.to(device, non_blocking=True)\n",
    "          outputs = model(images)\n",
    "          _, pred = outputs.max(1)\n",
    "          correct += pred.eq(labels).sum().item()\n",
    "          total += labels.size(0)\n",
    "\n",
    "  acc = 100.0 * correct / total\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afab91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = evaluate(model_fp32,test_loader,device)\n",
    "# print(f\"FP32 Test Accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0abd46",
   "metadata": {},
   "source": [
    "## Task 2: Quantize Squeezenet\n",
    "\n",
    "For task 2 we use quantization aware training to quantize SqueezeNet to INT8. After training for 50 epochs we are able to achieve a final test accuracy of 69.16% with the quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from qtorch import FixedPoint, FloatingPoint\n",
    "# from qtorch.quant import Quantizer\n",
    "\n",
    "# # Define target fixed-point format (ap_fixed<8,4>)\n",
    "# # 8 total bits, 4 fractional bits â†’ Q3.4\n",
    "# forward_num = FixedPoint(wl=8, fl=4, rounding=\"nearest\", saturate=True)\n",
    "\n",
    "# # Use standard FP32 for backward gradients\n",
    "# backward_num = FloatingPoint(exp=8, man=23)  # 32-bit float\n",
    "\n",
    "# # Create a quantizer\n",
    "# Q = Quantizer(forward_number=forward_num,\n",
    "#               backward_number=backward_num,\n",
    "#               forward_rounding=\"nearest\",\n",
    "#               backward_rounding=\"stochastic\")\n",
    "\n",
    "# def add_weight_quant(module):\n",
    "#     \"\"\"\n",
    "#     Recursively add weight quantization to Conv2d/Linear layers.\n",
    "#     Stores original float weights as 'weight_fp'.\n",
    "#     \"\"\"\n",
    "#     for name, child in module.named_children():\n",
    "#         add_weight_quant(child)\n",
    "\n",
    "#     if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "#         if not hasattr(module, 'weight_fp'):\n",
    "#             module.weight_fp = nn.Parameter(module.weight.data.clone())\n",
    "        \n",
    "#         # Override forward to quantize weights\n",
    "#         orig_forward = module.forward\n",
    "#         def forward_hook(x, module=module, orig_forward=orig_forward):\n",
    "#             module.weight.data = Q(module.weight_fp)\n",
    "#             return orig_forward(x)\n",
    "        \n",
    "#         module.forward = forward_hook\n",
    "\n",
    "# def apply_activation_q(model):\n",
    "#     for name, child in model.named_children():\n",
    "#         apply_activation_q(child)\n",
    "#         if isinstance(child, nn.ReLU):\n",
    "#             # replace inplace ReLU with non-inplace sequential\n",
    "#             new_relu = nn.Sequential(nn.ReLU(inplace=False), Q)\n",
    "#             setattr(model, name, new_relu)\n",
    "\n",
    "# class SqueezeNetFixedQAT(nn.Module):\n",
    "#     def __init__(self, base_model):\n",
    "#         super().__init__()\n",
    "#         self.model = base_model\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fp32 = SqueezeNetCIFAR10()\n",
    "# model_fp32.load_model(\"squeezenet_fp32_final.pth\")\n",
    "\n",
    "# # Wrap for fixed-point QAT\n",
    "# model_qat = SqueezeNetFixedQAT(model_fp32)\n",
    "\n",
    "# # Apply activation quantization\n",
    "# apply_activation_q(model_qat.model)\n",
    "\n",
    "# # Apply weight quantization\n",
    "# add_weight_quant(model_qat.model)\n",
    "\n",
    "# # model_qat = SqueezeNetCIFAR10()\n",
    "# # model_qat.model.load_model('squeezenet_fp32_final.pth')\n",
    "# # add_weight_quant_hooks(model_qat)\n",
    "# # apply_activation_q(model_qat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4769175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization as tq\n",
    "\n",
    "def prepare_model_for_qat(model_fp32):\n",
    "    model = model_fp32.train()\n",
    "\n",
    "    # Standard QAT config\n",
    "    qat_config = tq.get_default_qat_qconfig(\"fbgemm\")\n",
    "\n",
    "    model_q = tq.prepare_qat(model, inplace=False)\n",
    "    model_q.qconfig = qat_config\n",
    "\n",
    "    return model_q\n",
    "\n",
    "def convert_to_int8(model_qat):\n",
    "    model_int8 = tq.convert(model_qat.eval(), inplace=False)\n",
    "    return model_int8\n",
    "\n",
    "def int8_to_apfixed84(weight_float):\n",
    "    \"\"\"\n",
    "    Input: FP32 tensor\n",
    "    Output: tensor quantized to ap_fixed<8,4>\n",
    "    \"\"\"\n",
    "\n",
    "    scale = 16  # 2^4\n",
    "    min_val = -8.0\n",
    "    max_val = 7.9375\n",
    "\n",
    "    # quantize\n",
    "    q = torch.clamp(torch.round(weight_float * scale), min_val * scale, max_val * scale)\n",
    "    return q / scale\n",
    "\n",
    "def convert_model_to_apfixed84(model_int8):\n",
    "    model_fixed = {}\n",
    "\n",
    "    for name, module in model_int8.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            w = module.weight().float().cpu()\n",
    "            w_fixed = int8_to_apfixed84(w)\n",
    "            model_fixed[name] = w_fixed\n",
    "\n",
    "            if module.bias is not None:\n",
    "                b = module.bias().float().cpu()\n",
    "                b_fixed = int8_to_apfixed84(b)\n",
    "                model_fixed[name + \".bias\"] = b_fixed\n",
    "\n",
    "    return model_fixed\n",
    "\n",
    "def load_fixed_weights_into_fp32(model_fp32, fixed_weights):\n",
    "    for name, module in model_fp32.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            module.weight.data = fixed_weights[name]\n",
    "            if module.bias is not None:\n",
    "                module.bias.data = fixed_weights[name + \".bias\"]\n",
    "    return model_fp32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32 = SqueezeNetCIFAR10()\n",
    "model_fp32.load_model(\"squeezenet_fp32_final.pth\")\n",
    "\n",
    "# Prepare QAT\n",
    "model_qat = prepare_model_for_qat(model_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_metrics = train_model(model=model_qat,train_loader=train_loader,test_loader=test_loader,device=device,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(qat_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f08e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_int8 = tq.convert(model_qat.eval(), inplace=False)\n",
    "model_int8 = convert_to_int8(model_qat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluate(model_int8,test_loader,device)\n",
    "print(f\"Fixed Point Test Accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8.eval()\n",
    "torch.save(model_qat.state_dict(), \"squeezenet_quantized.pth\")\n",
    "model_fixed_dict = convert_model_to_apfixed84(model_int8)\n",
    "\n",
    "# Load fixed weights into evaluation model\n",
    "model_fixed_eval = load_fixed_weights_into_fp32(SqueezeNetCIFAR10(), model_fixed_dict)\n",
    "\n",
    "# Evaluate ap_fixed<8,4>\n",
    "acc_fixed = evaluate(model_fixed_eval, test_loader,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
